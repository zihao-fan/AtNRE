{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation file\n",
    "relation_dict_path = 'data/relation_dict.pkl'\n",
    "# train file\n",
    "label_random_path = 'data/label_random.pkl'\n",
    "label_gabor_path = 'data/label_gabor.pkl'\n",
    "unlabel_data_file = 'data/DS_noise.pkl'\n",
    "# eval file\n",
    "group_eval_data_file = 'data/slim_test_group.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(relation_dict_path, 'rb')\n",
    "relation_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f=open(label_random_path, 'rb')\n",
    "label_random = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f=open(label_gabor_path, 'rb')\n",
    "label_gabor = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f=open(unlabel_data_file, 'rb')\n",
    "unlabel_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f=open(group_eval_data_file, 'rb')\n",
    "group_eval_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'per:origin': 1, '/people/person/place_of_birth': 2, 'NA': 0, '/people/person/place_lived': 3, '/people/deceased_person/place_of_death': 4}\n"
     ]
    }
   ],
   "source": [
    "print(relation_dict)\n",
    "\n",
    "def get_relation_counter():\n",
    "    relation_counter = {}\n",
    "    for r in list(relation_dict.keys()):\n",
    "        relation_counter[r] = 0\n",
    "    return relation_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NA'}\n",
      "[['with', 'the', 'end', 'of', 'the', 'northern', 'ireland', 'conflict', 'and', 'the', 'power-sharing', 'agreement', 'of', 'the', 'rev', '.', 'ian', 'paisley', 'of', 'the', 'democratic', 'unionist', 'party', 'and', 'martin', 'mcguinness', 'of', 'sinn', 'fein', ',', 'this', 'area', 'of', 'county', 'meath', 'has', 'rapidly', 'become', 'the', 'most', 'disputed', 'terrain', 'in', 'the', 'country', '.'], ['it', \"'s\", 'a', 'day', 'that', 'no', 'one', 'thought', 'ever', 'to', 'see', ',', 'ian', 'paisley', 'of', 'the', 'democratic', 'unionist', 'party', 'in', 'government', 'with', 'martin', 'mcguinness', 'of', 'sinn', 'fein', ',', '\"', 'said', 'sydney', 'elliott', ',', 'a', 'professor', 'of', 'politics', 'at', 'queen', \"'s\", 'university', 'here', '.', '\"'], ['ex-foes', 'sworn', 'in', 'to', 'lead', 'in', 'northern', 'ireland', 'from', 'left', ',', 'martin', 'mcguinness', ',', 'deputy', 'first', 'minister', 'of', 'the', 'northern', 'ireland', 'executive', 'government', ';', 'the', 'rev', '.', 'ian', 'paisley', ',', 'the', 'government', \"'s\", 'first', 'minister', ';', 'prime', 'minister', 'tony', 'blair', 'of', 'britain', ';', 'and', 'prime', 'minister', 'bertie', 'ahern', 'of', 'ireland', 'left', 'the', 'stormont', 'parliament', 'building', 'in', 'belfast', 'after', 'mr.', 'mcguinness', 'and', 'mr.', 'paisley', ',', 'former', 'enemies', ',', 'were', 'sworn', 'in', 'to', 'forge', 'a', 'government', '.'], ['mr.', 'ahern', 'is', 'also', 'hoping', 'for', 'an', 'electoral', 'push', 'from', 'the', 'power-sharing', 'government', 'in', 'northern', 'ireland', ',', 'led', 'by', 'the', 'protestant', 'firebrand', 'ian', 'paisley', ',', 'with', 'martin', 'mcguinness', 'of', 'sinn', 'fein', 'as', 'his', 'deputy', '.'], ['watched', 'by', 'dignitaries', 'from', 'britain', ',', 'ireland', ',', 'the', 'united', 'states', 'and', 'elsewhere', ',', 'the', 'rev', '.', 'ian', 'paisley', ',', 'leader', 'of', 'the', 'democratic', 'unionists', ',', 'the', 'dominant', 'party', 'among', 'northern', 'ireland', \"'s\", 'protestants', ',', 'and', 'martin', 'mcguinness', ',', 'of', 'the', 'republican', 'and', 'mainly', 'catholic', 'sinn', 'fein', 'party', ',', 'were', 'sworn', 'in', 'as', 'leader', 'and', 'deputy', 'leader', ',', 'respectively', ',', 'of', 'the', 'northern', 'ireland', 'executive', 'government', '.', '\"'], ['they', 'have', 'led', 'to', 'the', 'alice', 'in', 'wonderland', 'situation', 'we', 'now', 'have', ',', 'in', 'which', 'the', 'government', 'of', 'northern', 'ireland', 'has', 'been', 'placed', 'in', 'the', 'hands', 'of', 'two', 'sworn', 'enemies', '--', 'the', 'extreme', 'protestant', 'minister', 'ian', 'paisley', 'and', 'the', 'former', 'i.r.a', '.', 'guerrilla', 'martin', 'mcguinness', '.']] 6\n",
      "[(15, 18, 24, 26), (12, 14, 22, 24), (26, 29, 11, 13), (22, 24, 26, 28), (16, 19, 36, 38), (35, 37, 43, 45)]\n"
     ]
    }
   ],
   "source": [
    "sample = list(group_eval_data.keys())[0]\n",
    "print(group_eval_data[sample][0])\n",
    "print(group_eval_data[sample][1], len(group_eval_data[sample][1]))\n",
    "print(group_eval_data[sample][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "nlp = spacy.load('en')\n",
    "pos_vocab = {}\n",
    "dep_vocab = {}\n",
    "\n",
    "def get_pos_dep(tok_list):\n",
    "    global pos_vocab\n",
    "    global dep_vocab\n",
    "    doc = Doc(nlp.vocab, words=tok_list)\n",
    "    pos_list = []\n",
    "    dep_list = []\n",
    "    nlp.tagger(doc)\n",
    "    nlp.parser(doc)\n",
    "    for tok in doc:\n",
    "        pos_list.append(tok.tag_)\n",
    "        dep_list.append(tok.dep_)\n",
    "        if tok.tag_ not in pos_vocab:\n",
    "            pos_vocab[tok.tag_] = len(pos_vocab)\n",
    "        if tok.dep_ not in dep_vocab:\n",
    "            dep_vocab[tok.dep_] = len(dep_vocab)\n",
    "    assert len(tok_list) == len(pos_list), \"Tok list lenght doesn't match with pos length\"\n",
    "    assert len(tok_list) == len(dep_list)\n",
    "    return pos_list, dep_list\n",
    "\n",
    "def label_data_add_tag_dep(data):\n",
    "    T, E, P, R = data\n",
    "    POS = []\n",
    "    DEP = []\n",
    "    for tok_list in T:\n",
    "        pos, dep = get_pos_dep(tok_list)\n",
    "        POS.append(pos)\n",
    "        DEP.append(dep)\n",
    "    return (T, E, P, R, POS, DEP)\n",
    "\n",
    "def group_data_add_tag_dep(group):\n",
    "    data = group.copy()\n",
    "    all_keys = list(data.keys())\n",
    "    for key in all_keys:\n",
    "        sentences_list = data[key][1]\n",
    "        pos_list = []\n",
    "        dep_list = []\n",
    "        for sentence in sentences_list:\n",
    "            pos, dep = get_pos_dep(sentence)\n",
    "            pos_list.append(pos)\n",
    "            dep_list.append(dep)\n",
    "        data[key].append(pos_list)\n",
    "        data[key].append(dep_list)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_random_new = label_data_add_tag_dep(label_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_gabor_new = label_data_add_tag_dep(label_gabor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabel_data_new = label_data_add_tag_dep(unlabel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_eval_data_new = group_data_add_tag_dep(group_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file_path, data):\n",
    "    with open(file_path, 'wb'):\n",
    "        pickle.dump(data)\n",
    "    print('Done save to', file_path)\n",
    "\n",
    "save_pickle('data/label_random_new.pkl', label_random_new)\n",
    "save_pickle('data/label_gabor_new.pkl', label_gabor_new)\n",
    "save_pickle('data/DS_noise_new.pkl', unlabel_data_new)\n",
    "save_pickle('data/slim_test_group_new.pkl', group_eval_data_new)\n",
    "save_pickle('data/pos_vocab.pkl', pos_vocab)\n",
    "save_pickle('data/dep_vocab.pkl', dep_vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
